{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c553486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from typing import Annotated,TypedDict\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool\n",
    "import os\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Optional\n",
    "\n",
    "def now_iso():\n",
    "    \"\"\"Return current datetime in ISO format including time and timezone if available.\"\"\"\n",
    "    return datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "\n",
    "class AnalysisSource(BaseModel):\n",
    "    source_name:  Optional[str] = Field(..., description=\"Name of the data source, e.g., Google, Bing, Reddit, Google Finance\")\n",
    "    analysis: str = Field(..., description=\"Analysis result or summary from this source\")\n",
    "    source_link: Optional[str] = Field(..., description=\"Direct link to the information or post\")\n",
    "\n",
    "\n",
    "class LLMAnalysisResult(BaseModel):\n",
    "    sources: list[AnalysisSource] = Field(..., description=\"List of sources with analysis and URLs\")\n",
    "    synthesized_answer: str = Field(..., description=\"LLM's synthesized answer using all sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ee0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGoogleGenerativeAI(model='gemini-2.5-flash',api_key=os.getenv('GEMINI_API_KEY'),async_client_running=True,verbose=True)\n",
    "analysing_llm=llm.with_structured_output(AnalysisSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c7f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Ethics in AI is a critical and rapidly evolving field, grappling with the profound moral implications as intelligent systems become increasingly integrated into every facet of society. The imperative is to ensure these powerful technologies align with human values and principles, preventing potential harms while maximizing societal benefit. Key concerns revolve around algorithmic bias, where datasets can perpetuate or amplify societal inequalities, leading to discriminatory outcomes in areas like hiring, lending, or criminal justice. Equally vital are issues of transparency and explainability, as complex models often operate as 'black boxes,' making it difficult to understand *why* a decision was made, undermining trust and accountability. Furthermore, questions of privacy, data security, and the autonomous nature of some AI systems raise serious moral dilemmas regarding surveillance, control, and the erosion of human agency. Without robust ethical frameworks and governance, developed through a proactive, multi-stakeholder approach, AI could inadvertently exacerbate existing societal divides, erode trust in institutions, and even pose risks to fundamental human rights, underscoring the urgent need for responsible innovation.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--70068a4c-2c36-4e48-acf7-8398f4780260-0', usage_metadata={'input_tokens': 9, 'output_tokens': 1210, 'total_tokens': 1219, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1006}})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm.ainvoke('give me aa para about ethics in ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis=await analysing_llm.ainvoke(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5531fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No specific link provided, this is a general statement.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.source_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e972f",
   "metadata": {},
   "source": [
    "## Define state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0df997",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(TypedDict):\n",
    "    messages:Annotated[str,add_messages]\n",
    "    user_question:str|None\n",
    "    google_search_results:str|None\n",
    "    google_finance_results:str|None\n",
    "    bing_search_results:str|None\n",
    "    reddit_search_results:str|None\n",
    "    selected_reddit_urls:list[str]|None\n",
    "    reddit_posts:str|None\n",
    "    google_analysis:str\n",
    "    bing_analysis:str\n",
    "    reddit_analysis:str\n",
    "    google_finance_analysis:str\n",
    "    synthesized_answer:str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74aec2c",
   "metadata": {},
   "source": [
    "# NODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def google_search(state:ResearchState)->ResearchState:\n",
    "    return state\n",
    "\n",
    "\n",
    "def bing_search(state:ResearchState)->ResearchState:\n",
    "    return state\n",
    "\n",
    "\n",
    "def reddit_search(state:ResearchState)->ResearchState:\n",
    "    return state\n",
    "\n",
    "def twitter_search(state: ResearchState) -> ResearchState:\n",
    "    return state\n",
    "\n",
    "def google_finance_search(state:ResearchState)->ResearchState:\n",
    "    return state\n",
    "\n",
    "def analysis_google_results(state:ResearchState)->ResearchState:\n",
    "    return state\n",
    "\n",
    "\n",
    "def analysis_bing_results(state:ResearchState)->ResearchState:\n",
    "    return state\n",
    "\n",
    "\n",
    "def analysis_reddit_results(state:ResearchState)->ResearchState:\n",
    "    return state\n",
    "\n",
    "\n",
    "def analyze_results_results(state:ResearchState)->ResearchState:\n",
    "    return state\n",
    "    \n",
    "\n",
    "def synthesize_results(state:ResearchState)->ResearchState:\n",
    "    return state\n",
    "\n",
    "\n",
    "def final_results(state:ResearchState)->ResearchState:\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d295182",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GoogleSearch' from 'serpapi' (/Users/divyyadav/miniforge3/envs/deep_env/lib/python3.11/site-packages/serpapi/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mserpapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleSearch\n\u001b[32m      3\u001b[39m params = {\n\u001b[32m      4\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgoogle_finance\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mq\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mGOOGL:NASDAQ\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: os.getenv(\u001b[33m'\u001b[39m\u001b[33mSERP_API\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m }\n\u001b[32m      9\u001b[39m search = GoogleSearch(params)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'GoogleSearch' from 'serpapi' (/Users/divyyadav/miniforge3/envs/deep_env/lib/python3.11/site-packages/serpapi/__init__.py)"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "params = {\n",
    "  \"engine\": \"google_finance\",\n",
    "  \"q\": \"GOOGL:NASDAQ\",\n",
    "  \"api_key\": os.getenv('SERP_API')\n",
    "}\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c1894",
   "metadata": {},
   "source": [
    "# GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(ResearchState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fedd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node(\"google_search\", google_search)\n",
    "graph.add_node(\"bing_search\", bing_search)\n",
    "graph.add_node(\"reddit_search\", reddit_search)\n",
    "graph.add_node(\"analysis_google_results\", analysis_google_results)\n",
    "graph.add_node(\"analysis_bing_results\", analysis_bing_results)\n",
    "graph.add_node(\"analysis_reddit_results\", analysis_reddit_results)\n",
    "graph.add_node(\"analyze_results_results\", analyze_results_results)\n",
    "graph.add_node(\"synthesize_results\", synthesize_results)\n",
    "graph.add_node(\"final_results\", final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edge(START, \"google_search\")\n",
    "graph.add_edge(START, \"bing_search\")\n",
    "graph.add_edge(START, \"reddit_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import asyncpraw\n",
    "import asyncio\n",
    "import os\n",
    "from aiocache import caches\n",
    "\n",
    "def chunk_list(data, chunk_size):\n",
    "    for i in range(0,len(data),chunk_size):\n",
    "        yield data[i:i+chunk_size]\n",
    "\n",
    "# Load Reddit API credentials from environment variables (with default fallback)\n",
    "client_id = os.getenv('REDDIT_CLIENT_ID')\n",
    "client_secret = os.getenv('REDDIT_CLIENT_SECRET')\n",
    "user_agent = 'dp by /u/Temporary_Version105'\n",
    "\n",
    "# Reset aiocache state (helpful in Jupyter notebooks)\n",
    "caches._caches.clear()\n",
    "caches._config.clear()\n",
    "\n",
    "# Configure aiocache to use in-memory cache with JSON serialization\n",
    "caches.set_config({\n",
    "    'default': {\n",
    "        'cache': 'aiocache.backends.memory.SimpleMemoryCache',\n",
    "        'serializer': {'class': 'aiocache.serializers.PickleSerializer'},\n",
    "        'ttl': 3600\n",
    "    }\n",
    "})\n",
    "\n",
    "async def fetch_reddit_posts():\n",
    "    \"\"\"\n",
    "    Fetch 'hot' posts and top-level comments from r/finance and store in cache.\n",
    "    Skips posts if already cached. Stores post IDs for easy querying later.\n",
    "    \"\"\"\n",
    "    cache = caches.get('default')\n",
    "    print(\"Connecting to Reddit...\")\n",
    "    \n",
    "    reddit = asyncpraw.Reddit(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        user_agent=user_agent\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Get the finance subreddit\n",
    "        subreddit = await reddit.subreddit('finance')\n",
    "        post_processed = 0\n",
    "        post_ids = []\n",
    "\n",
    "        # Iterate over hot posts (limit 10 for demo)\n",
    "        async for post in subreddit.hot(limit=0):\n",
    "            post_processed += 1\n",
    "            post_id = post.id\n",
    "\n",
    "            # Keys for post and its comments\n",
    "            post_cache_key = f'posts{post_id}'\n",
    "            comments_cache_key = f'comments{post_id}'\n",
    "\n",
    "            # Check if this post and its comments are already cached\n",
    "            cached_post = await cache.get(post_cache_key)\n",
    "            cached_comments = await cache.get(comments_cache_key)\n",
    "\n",
    "            if cached_post and cached_comments:\n",
    "                print(f\"  > Using cached: {cached_post.get('title', 'No Title')[:20]}\")\n",
    "                continue\n",
    "\n",
    "            # Fetch data if not cached\n",
    "            else:\n",
    "                try:\n",
    "                    # Fully load post and expand all comments (no 'more')\n",
    "                    await post.load()\n",
    "                    await post.comments.replace_more(limit=0)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading post {post.id}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Collect up to 50 comments with key details\n",
    "                comments = []\n",
    "                for com in post.comments.list()[:20]:\n",
    "                    if hasattr(com, 'body') and com.body.strip():\n",
    "                        comments.append(\n",
    "                            {\n",
    "                                \"id\": com.id,\n",
    "                                \"body\": com.body,\n",
    "                                \"author\": str(getattr(com, \"author\", \"N/A\")),\n",
    "                                \"score\": getattr(com, \"score\", 0),\n",
    "                                \"depth\": com.depth,   \n",
    "                                \"controversiality\": com.controversiality,\n",
    "                                \"gilded\": com.gilded,\n",
    "                                \"total_awards_received\": com.total_awards_received,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                # Store post data with title, score, and comments\n",
    "                post_data = {\n",
    "                    \"title\": getattr(post, \"title\", \"N/A\"),\n",
    "                    \"score\": getattr(post, \"score\", 0),\n",
    "                    \"comments\": comments\n",
    "                }\n",
    "\n",
    "                # Track fetched post IDs\n",
    "                post_ids.append(post.id)\n",
    "\n",
    "                for idx, chunk in enumerate(chunk_list(comments, 200)):\n",
    "                    chunk_key = f\"{comments_cache_key}_chunk{idx}\"\n",
    "                    await cache.set(chunk_key, chunk, ttl=36000)\n",
    "\n",
    "                await cache.set(post_cache_key, post_data, ttl=3600)\n",
    "                await cache.set('all_post_ids', post_ids, ttl=3600)\n",
    "\n",
    "                print(f' post ids {post_ids} and their length {len(post_ids)}')\n",
    "                print(f\"  > Fetched and cached post {post_processed}: {post.title[:50]}...\")\n",
    "\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"Operation timed out.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Always close Reddit API connection\n",
    "        await reddit.close()  \n",
    "\n",
    "async def get_posts(postid):\n",
    "    \"\"\"\n",
    "    Retrieve a cached Reddit post by its ID.\n",
    "    Returns a dict with post and comments if found, or None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cache_instance = caches.get('default')\n",
    "        post_cache_key = f'posts{postid}'\n",
    "        posts = await cache_instance.get(post_cache_key)\n",
    "        if posts:\n",
    "            print(f\"  > Using cached data for post: {posts['title']}\")\n",
    "            return posts\n",
    "        else:\n",
    "            print('no posts found')\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting posts for postid {postid}: {e}\")\n",
    "        return None\n",
    "\n",
    "async def get_all_comments():\n",
    "    \"\"\"\n",
    "    Retrieve all cached comments from all posts currently stored in cache.\n",
    "    Returns a flat list of comments (good for analysis or language models).\n",
    "    \"\"\"\n",
    "    cache = caches.get('default')\n",
    "    \n",
    "    # Find all cached post IDs\n",
    "    post_ids_key = 'all_post_ids'\n",
    "    post_ids = await cache.get(post_ids_key) or []\n",
    "    \n",
    "    if not post_ids:\n",
    "        print(\"⚠️  No cached posts found. Run fetch_reddit_posts() first!\")\n",
    "        return []\n",
    "    \n",
    "    all_comments = []\n",
    "    print(f\"📥 Collecting comments from {len(post_ids)} posts...\\n\")\n",
    "    \n",
    "    # Gather all comments for each post (add post_id for provenance)\n",
    "    for post_id in post_ids:\n",
    "        comments_cache_key = f'comments{post_id}'\n",
    "        idx=0\n",
    "        comments = []\n",
    "        while True:\n",
    "            chunk = await cache.get(f\"{comments_cache_key}_chunk{idx}\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            comments.extend(chunk)\n",
    "            idx += 1\n",
    "        \n",
    "        if comments:\n",
    "            for comment in comments:\n",
    "                comment['post_id'] = post_id  # Track origin post\n",
    "                all_comments.append(comment)\n",
    "    \n",
    "    print(f\"✅ Total comments collected: {len(all_comments)}\")\n",
    "    return all_comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85c1981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Reddit...\n",
      "⚠️  No cached posts found. Run fetch_reddit_posts() first!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await fetch_reddit_posts()\n",
    "await get_all_comments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004a731",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb139e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from tavily import TavilyClient\n",
    "from deepagents import create_deep_agent\n",
    "\n",
    "api=os.environ[\"TAVILY_API_KEY\"]='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'\n",
    "\n",
    "tavily_client = TavilyClient(api_key=api)\n",
    "\n",
    "# Web search tool\n",
    "def internet_search(\n",
    "    query: str,\n",
    "    max_results: int = 5,\n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n",
    "    include_raw_content: bool = False,\n",
    "):\n",
    "    \"\"\"Run a web search\"\"\"\n",
    "    return tavily_client.search(\n",
    "        query,\n",
    "        max_results=max_results,\n",
    "        include_raw_content=include_raw_content,\n",
    "        topic=topic,\n",
    "    )\n",
    "\n",
    "\n",
    "# System prompt to steer the agent to be an expert researcher\n",
    "research_instructions = \"\"\"You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.\n",
    "\n",
    "You have access to an internet search tool as your primary means of gathering information.\n",
    "\n",
    "## `internet_search`\n",
    "\n",
    "Use this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.\n",
    "\"\"\"\n",
    "\n",
    "# Create the deep agent\n",
    "agent = create_deep_agent(\n",
    "    tools=[internet_search],\n",
    "    system_prompt=research_instructions,\n",
    "    model=llm,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21c9ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is deep agents by langgraph use web search ?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f5ad37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Deep Agents\" with LangGraph refers to a new approach to building more sophisticated and autonomous AI agents. Unlike traditional agents that follow a simple loop of calling tools, Deep Agents are designed to handle complex, long-running tasks by incorporating several key features:\n",
      "\n",
      "1.  **Planning:** This allows agents to strategize and stay on track for complex objectives.\n",
      "2.  **File system:** Agents can use a file system to store and retrieve context, enabling them to offload information and manage longer interactions.\n",
      "3.  **Sub-agents:** These are specialized agents that can be called upon to handle specific tasks, acting as focused specialists within a larger workflow.\n",
      "4.  **Prompting:** Detailed instructions and careful prompting are used to guide the agents and ensure they understand and execute tasks effectively.\n",
      "\n",
      "LangGraph is a library that helps orchestrate these long-running, multi-agent workflows. It provides the framework to combine these \"Deep Agent\" features, allowing developers to design, implement, and deploy agents capable of more advanced reasoning and task execution.\n",
      "\n",
      "LangChain Academy offers a free course on \"Deep Agents with LangGraph\" to teach these concepts and practical implementation. \"Deep Agents\" is available in both Python and JavaScript.\n",
      "{}\n",
      "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}\n",
      "ai\n",
      "None\n",
      "lc_run--bfa858ab-4585-4e6f-a990-eb737c84affe-0\n",
      "[]\n",
      "[]\n",
      "{'input_tokens': 10344, 'output_tokens': 251, 'total_tokens': 10595, 'input_token_details': {'cache_read': 4912}}\n"
     ]
    }
   ],
   "source": [
    "for results in result['messages'][-1]:\n",
    "    print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30a875e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is deep agents by langgraph use web search ?', additional_kwargs={}, response_metadata={}, id='20b9adf6-b999-44b1-86bf-3582ac8b5e72'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'internet_search', 'arguments': '{\"query\": \"deep agents langgraph\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--a5aa4cac-e8f7-4566-8a81-9bff7ca161bb-0', tool_calls=[{'name': 'internet_search', 'args': {'query': 'deep agents langgraph'}, 'id': '844a87fb-596f-402c-b88f-0f8288dd9f4a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5122, 'output_tokens': 87, 'total_tokens': 5209, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 69}}),\n",
       "  ToolMessage(content='{\"query\": \"deep agents langgraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.youtube.com/watch?v=EAwAJc0bD7o\", \"title\": \"LangChain Academy New Course: Deep Agents with LangGraph\", \"content\": \"LangChain Academy New Course: Deep Agents with LangGraph\\\\nLangChain\\\\n149000 subscribers\\\\n239 likes\\\\n7203 views\\\\n18 Sep 2025\\\\nMany agents today follow the same simple pattern: run in a loop, call tools. That architecture works well enough, but it breaks down as tasks get more complex.\\\\n\\\\nToday, companies of all sizes – from startups to large enterprises – are building their own Deep Agents.\\\\n\\\\nThese agents dive deeper. They’re able to plan complex tasks and carry them out over longer time horizons.\\\\n\\\\nThere are four key features that set Deep Agents apart from a regular agent:\\\\n\\\\n1. Planning – keeps agents on track\\\\n2. File system – allows agents to offload context\\\\n3. Sub-agents – act as focused specialists\\\\n4. Prompting – provides agents with detailed instructions\\\\n\\\\nOur latest LangChain Academy course, Deep Agents with LangGraph, shows you how to combine these pieces with LangGraph to orchestrate long-running, multi-agent workflows.\\\\n\\\\nBy the end, you’ll have the skills to design, implement, and deploy your own Deep Agent.\\\\n\\\\nEnroll for free: https://academy.langchain.com/courses/deep-agents-with-langgraph/?utm_medium=social&utm_source=youtube&utm_campaign=q3-2025_deep-agents-course_co\\\\n\\\\nLearn more about LangGraph: https://www.langchain.com/langgraph/?utm_medium=social&utm_source=youtube&utm_campaign=q3-2025_deep-agents-course_co\\\\n5 comments\\\\n\", \"score\": 0.8921218, \"raw_content\": null}, {\"url\": \"https://docs.langchain.com/labs/deep-agents/overview\", \"title\": \"Deep Agents - Docs by LangChain\", \"content\": \"Deep Agents - Docs by LangChain [Skip to main content](https://docs.langchain.com/labs/deep-agents/overview#content-area) Our new LangChain Academy course on Deep Agents is now live! [Enroll for free](https://academy.langchain.com/courses/deep-agents-with-langgraph/?utm_medium=internal&utm_source=docs&utm_campaign=q3-2025_deep-agents-course_co). [Docs by LangChain home page![Image 1: light logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-teal.svg?fit=max&auto=format&n=Xbr8HuVd9jPi6qTU&q=85&s=16111530672bf976cb54ef2143478342)![Image 2: dark logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-lilac.svg?fit=max&auto=format&n=Xbr8HuVd9jPi6qTU&q=85&s=b70fb1a2208670492ef94aef14b680be)](https://docs.langchain.com/)Python *   [Overview](https://docs.langchain.com/labs/deep-agents/overview) *   [Quickstart](https://docs.langchain.com/labs/deep-agents/quickstart) *   [Configuration options](https://docs.langchain.com/labs/deep-agents/configuration-options) *   [Built-in components](https://docs.langchain.com/labs/deep-agents/built-in-components) [Enroll for free](https://academy.langchain.com/courses/deep-agents-with-langgraph/?utm_medium=internal&utm_source=docs&utm_campaign=q3-2025_deep-agents-course_co). [Docs by LangChain home page![Image 3: light logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-teal.svg?fit=max&auto=format&n=Xbr8HuVd9jPi6qTU&q=85&s=16111530672bf976cb54ef2143478342)![Image 4: dark logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-lilac.svg?fit=max&auto=format&n=Xbr8HuVd9jPi6qTU&q=85&s=b70fb1a2208670492ef94aef14b680be)](https://docs.langchain.com/) *   [GitHub](https://github.com/langchain-ai) [Overview](https://docs.langchain.com/labs)[Deep Agents](https://docs.langchain.com/labs/deep-agents/overview)[Open SWE](https://docs.langchain.com/labs/swe)[Open Agent Platform](https://docs.langchain.com/labs/oap) [Overview](https://docs.langchain.com/labs)[Deep Agents](https://docs.langchain.com/labs/deep-agents/overview)[Open SWE](https://docs.langchain.com/labs/swe)[Open Agent Platform](https://docs.langchain.com/labs/oap) *   [GitHub](https://github.com/langchain-ai) *   [Key features](https://docs.langchain.com/labs/deep-agents/overview#key-features) *   [Installation](https://docs.langchain.com/labs/deep-agents/overview#installation) *   [Implementations](https://docs.langchain.com/labs/deep-agents/overview#implementations) *   [Acknowledgements](https://docs.langchain.com/labs/deep-agents/overview#acknowledgements) [Get started](https://docs.langchain.com/labs/deep-agents/overview) [\\u200b](https://docs.langchain.com/labs/deep-agents/overview#key-features) [\\u200b](https://docs.langchain.com/labs/deep-agents/overview#installation) [\\u200b](https://docs.langchain.com/labs/deep-agents/overview#implementations) Deep Agents is available in both [**Python**](https://github.com/hwchase17/deepagents) and [**JavaScript**](https://www.npmjs.com/package/deepagents). [\\u200b](https://docs.langchain.com/labs/deep-agents/overview#acknowledgements) [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/labs/deep-agents/overview.mdx) [Quickstart](https://docs.langchain.com/labs/deep-agents/quickstart) [Docs by LangChain home page![Image 5: light logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-teal.svg?fit=max&auto=format&n=Xbr8HuVd9jPi6qTU&q=85&s=16111530672bf976cb54ef2143478342)![Image 6: dark logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-lilac.svg?fit=max&auto=format&n=Xbr8HuVd9jPi6qTU&q=85&s=b70fb1a2208670492ef94aef14b680be)](https://docs.langchain.com/) [github](https://github.com/langchain-ai)[x](https://x.com/LangChainAI)[linkedin](https://www.linkedin.com/company/langchain/)[youtube](https://www.youtube.com/@LangChain) [github](https://github.com/langchain-ai)[x](https://x.com/LangChainAI)[linkedin](https://www.linkedin.com/company/langchain/)[youtube](https://www.youtube.com/@LangChain)\", \"score\": 0.8296166, \"raw_content\": null}, {\"url\": \"https://www.langchain.com/langgraph\", \"title\": \"LangGraph - LangChain\", \"content\": \"[![Image 3](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e27023585643370a6471_icons.svg) LangChain Quick start agents with any model provider](https://www.langchain.com/langchain)[![Image 4](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e270417338c7f027082d_d035ce400e48f9bc4dd0578d0e3e3211_icons-1.svg) LangGraph Build custom agents with low-level control](https://www.langchain.com/langgraph)[![Image 5](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68f20863b71dbae1af829979_DeepAgents.svg) Deep Agents New Use planning, memory, and sub-agents for complex, long-running tasks](https://github.com/langchain-ai/deepagents) [![Image 6](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e270df09334914882b88_Frame%209.svg) Observability Debug and monitor in-depth traces](https://www.langchain.com/langsmith/observability)[![Image 7](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e270f9e8de1d368764a8_Frame%20206.svg) Evaluation Iterate on prompts and models](https://www.langchain.com/langsmith/evaluation)[![Image 8](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68e8e2709eef27fc61465416_Frame%20100039.svg) Deployment Ship and scale agents in production](https://www.langchain.com/langsmith/deployment) [See LangGraph use cases in production](https://www.langchain.com/built-with-langgraph) ![Image 11](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1d39b2c6c806093f171_GitLab_logo_(2)%201.svg) ![Image 12](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg) ![Image 17](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg) ![Image 21](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1d39b2c6c806093f171_GitLab_logo_(2)%201.svg) ![Image 22](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg) ![Image 27](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg) ![Image 31](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1d39b2c6c806093f171_GitLab_logo_(2)%201.svg) ![Image 32](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg) ![Image 37](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg) ![Image 42](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg) ![Image 47](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg) ![Image 50](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b080e4b3ca12dc5d5d439_Langgraph%20UI-2.webp) ![Image 52](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68663ca715b9bd5d707bee71_Modified-Human-in-the-loop_white.gif) ![Image 53](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6865b895f061b6f892568ff6_Modified-Customizable-Agent-Architectures_white.gif) [See different agent architectures](https://docs.langchain.com/oss/python/langgraph/workflows-agents) [Learn about agent memory](https://docs.langchain.com/oss/python/langgraph/add-memory) ![Image 55](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6865b8b7df5aea00af3a4554_Modified-Streaming-intermediate-steps_white.gif) [See how to use streaming](https://docs.langchain.com/oss/python/langgraph/streaming) [![Image 58](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/678e35d6c553c4fb20f9b753_Frame%2099644.webp)![Image 59](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6787ae0bce5c99dd808545ce_card%202.webp)](https://academy.langchain.com/courses/intro-to-langgraph) ![Image 61](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b26a1b4576291d6a9335b_garrett%20spong%201.webp) ![Image 63](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b265bed5f5a9d26d6b7d6_andres%20torres%201.webp) ![Image 65](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679e2d31352c6bd56c84280_ally.png) ![Image 67](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b26a1b4576291d6a9335b_garrett%20spong%201.webp) ![Image 69](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b265bed5f5a9d26d6b7d6_andres%20torres%201.webp) ![Image 71](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679e2d31352c6bd56c84280_ally.png) ![Image 72](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65c6a38f9c53ec71f5fc73de_langchain-word.svg)\", \"score\": 0.82895297, \"raw_content\": null}, {\"url\": \"https://blog.langchain.com/doubling-down-on-deepagents/\", \"title\": \"Doubling down on DeepAgents - LangChain Blog\", \"content\": \"In this blog we want to talk about whats new in 0.2 release compared to the launch, as well as when to use `deepagents` (vs `langchain` or `langgraph`) You could have a local filesystem as a base backend, but then map all file operations in `/memories/` directory to an s3 backed \\\\\"virtual filesystem\\\\\", allowing your agent to add things there and have them persist beyond your computer. DeepAgents is great for building more autonomous, long running agents where you want to take advantage of built in things like planning tools, filesystem, etc. They built on top of each other - `deepagents` is built on top of `langchain`\\'s agent abstraction, which is turn is built on top of `langgraph`\\'s agent runtime.\", \"score\": 0.81979275, \"raw_content\": null}, {\"url\": \"https://academy.langchain.com/courses/deep-agents-with-langgraph\", \"title\": \"Project: Deep Agents with LangGraph - LangChain Academy\", \"content\": \"## Project: Deep Agents with LangGraph Learn the fundamental characteristics of Deep Agents and how to implement your own Deep Agent for complex, long-running tasks. Enroll for free Watch Intro Video ## Course curriculum 3. Course Transcripts 2. Course Overview 3. Module 1 Feedback 3. Create Agent 4. Module 2 Feedback 4. Module 3 Feedback 4. Module 4 Feedback 4. Module 5 Feedback 3. Full Agent 4. Module 6 Feedback 3. Module 7 Feedback 4. End of Course Feedback ### About this course * Free * 1 hour of video content ## Ready to starts shipping reliable agents faster? Our platform provides tools for every step of the agent development lifecycle    Learn alongside other builders at in-person LangChain meetups.\", \"score\": 0.81347597, \"raw_content\": null}], \"response_time\": 0.7, \"request_id\": \"9c5a30a0-aeb8-467b-93db-7fcc41872677\"}', name='internet_search', id='6aaec3fe-226b-47d8-8b85-d8f0dc928eae', tool_call_id='844a87fb-596f-402c-b88f-0f8288dd9f4a'),\n",
       "  AIMessage(content='\"Deep Agents\" with LangGraph refers to a new approach to building more sophisticated and autonomous AI agents. Unlike traditional agents that follow a simple loop of calling tools, Deep Agents are designed to handle complex, long-running tasks by incorporating several key features:\\n\\n1.  **Planning:** This allows agents to strategize and stay on track for complex objectives.\\n2.  **File system:** Agents can use a file system to store and retrieve context, enabling them to offload information and manage longer interactions.\\n3.  **Sub-agents:** These are specialized agents that can be called upon to handle specific tasks, acting as focused specialists within a larger workflow.\\n4.  **Prompting:** Detailed instructions and careful prompting are used to guide the agents and ensure they understand and execute tasks effectively.\\n\\nLangGraph is a library that helps orchestrate these long-running, multi-agent workflows. It provides the framework to combine these \"Deep Agent\" features, allowing developers to design, implement, and deploy agents capable of more advanced reasoning and task execution.\\n\\nLangChain Academy offers a free course on \"Deep Agents with LangGraph\" to teach these concepts and practical implementation. \"Deep Agents\" is available in both Python and JavaScript.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--bfa858ab-4585-4e6f-a990-eb737c84affe-0', usage_metadata={'input_tokens': 10344, 'output_tokens': 251, 'total_tokens': 10595, 'input_token_details': {'cache_read': 4912}})]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162176b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
